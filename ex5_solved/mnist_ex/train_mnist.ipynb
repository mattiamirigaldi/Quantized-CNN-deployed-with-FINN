{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d131311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e56698ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples in each set: train = 60000, test = 10000\n",
      "Shape of one input sample: torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "\n",
    "import torch, torchvision, copy\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "transform_train = transforms.Compose([transforms.ToTensor()])\n",
    "transform_test = transforms.Compose([transforms.ToTensor()])\n",
    "training_data = datasets.FashionMNIST(root=\"/workspace/finn/notebooks/mnist_ex/data2/FashionMNIST/raw\", train=True, download=False, transform=transform_train)\n",
    "test_data = datasets.FashionMNIST(root=\"/workspace/finn/notebooks/mnist_ex/data2/FashionMNIST/raw\", train=False, download=False, transform=transform_test)\n",
    "print(\"Samples in each set: train = %d, test = %s\" % (len(training_data), len(test_data))) \n",
    "print(\"Shape of one input sample: \" +  str(training_data[0][0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33d8beac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape for 1 batch: torch.Size([32, 1, 28, 28])\n",
      "Label shape for 1 batch: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "#divide in batches\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "batch_size = 32\n",
    "# dataset loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)   \n",
    "count = 0\n",
    "for x,y in train_dataloader:\n",
    "    print(\"Input shape for 1 batch: \" + str(x.shape))\n",
    "    print(\"Label shape for 1 batch: \" + str(y.shape))\n",
    "    count += 1\n",
    "    if count == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ec353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model declaration \n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.quant import Int8Bias as BiasQuant\n",
    "from brevitas.quant import Uint8ActPerTensorFloat as ActQuant\n",
    "from brevitas.quant import Int8WeightPerTensorFloat as WeighQuant\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "weight_bitx = 8\n",
    "act_bitx = 8\n",
    "bias_bitx = 8\n",
    "\n",
    "model = nn.Sequential(\n",
    "    #qnn.QuantIdentity(bit_width=act_bitx, return_quant_tensor=True),\n",
    "    qnn.QuantConv2d(in_channels=1, out_channels=3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2),\n",
    "                                     bias=False, weight_bit_width=weight_bitx, weight_quant=WeighQuant,\n",
    "                                     bias_quant=BiasQuant, return_quant_tensor=True),\n",
    "    qnn.QuantReLU(bit_width=act_bitx, act_quant=ActQuant, return_quant_tensor=True),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    qnn.QuantConv2d(in_channels=3, out_channels=8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2),\n",
    "                                     bias=False, weight_bit_width=weight_bitx, bias_quant=BiasQuant,\n",
    "                                     weight_quant=WeighQuant, return_quant_tensor=True),\n",
    "    qnn.QuantReLU(bit_width=act_bitx, act_quant=ActQuant, return_quant_tensor=True),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    qnn.QuantConv2d(in_channels=8, out_channels=16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2),\n",
    "                                     bias=False, weight_bit_width=weight_bitx, bias_quant=BiasQuant,\n",
    "                                     weight_quant=WeighQuant, return_quant_tensor=True),\n",
    "    qnn.QuantReLU(bit_width=act_bitx, act_quant=ActQuant, return_quant_tensor=True),\n",
    "    nn.Flatten(),\n",
    "    qnn.QuantLinear(in_features=16*7*7, out_features=10, bias=True, weight_bit_width=weight_bitx,\n",
    "                                   weight_quant=WeighQuant, bias_quant=BiasQuant, return_quant_tensor=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc6edc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test functions\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    losses = []\n",
    "    # ensure model is in training mode\n",
    "    model.train()    \n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):        \n",
    "        inputs, target = data\n",
    "        optimizer.zero_grad()   \n",
    "                \n",
    "        # forward pass\n",
    "        output = model(inputs.float())\n",
    "        loss = criterion(output, target)#.unsqueeze(1))\n",
    "        \n",
    "        # backward pass + run optimizer to update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # keep track of loss value\n",
    "        losses.append(loss.data.numpy()) \n",
    "           \n",
    "    return losses\n",
    "\n",
    "\n",
    "\n",
    "def test(model, test_loader):    \n",
    "    # ensure model is in eval mode\n",
    "    model.eval() \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, target = data\n",
    "            output_orig = model(inputs.float())\n",
    "            # run the output through sigmoid\n",
    "            #output = torch.sigmoid(output_orig)  \n",
    "            # compare against a threshold of 0.5 to generate 0/1\n",
    "            #pred = (output.detach().numpy() > 0.5) * 1\n",
    "            target = target.float()\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(output_orig.argmax(1).reshape(-1).tolist())\n",
    "        \n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4df742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training settings\n",
    "num_epochs = 10\n",
    "lr = 0.001 \n",
    "\n",
    "def display_loss_plot(losses, title=\"Training loss\", xlabel=\"Iterations\", ylabel=\"Loss\"):\n",
    "    x_axis = [i for i in range(len(losses))]\n",
    "    plt.plot(x_axis,losses)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "    \n",
    "# loss criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70998afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss = 0.239489 test accuracy = 0.898300: 100%|██████████| 10/10 [03:18<00:00, 19.82s/it]\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "running_loss = []\n",
    "running_test_acc = []\n",
    "t = trange(num_epochs, desc=\"Training loss\", leave=True)\n",
    "\n",
    "for epoch in t:\n",
    "        loss_epoch = train(model, train_dataloader, optimizer,criterion)\n",
    "        test_acc = test(model, test_dataloader)\n",
    "        t.set_description(\"Training loss = %f test accuracy = %f\" % (np.mean(loss_epoch), test_acc))\n",
    "        t.refresh() # to show immediately the update           \n",
    "        running_loss.append(loss_epoch)\n",
    "        running_test_acc.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f855d1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8983"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing\n",
    "test(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c21324f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Brevitas model to disk\n",
    "torch.save(model.state_dict(), \"state_dict_self-trained.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5d69efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model_fmnist_notebook.onnx\n"
     ]
    }
   ],
   "source": [
    "import brevitas.onnx as bo\n",
    "from brevitas.quant_tensor import QuantTensor\n",
    "\n",
    "ready_model_filename = \"model_fmnist_notebook.onnx\"\n",
    "input_shape = (1, 1, 28, 28)\n",
    "\n",
    "\n",
    "bo.export_finn_onnx(\n",
    "    model, export_path=ready_model_filename, input_shape=input_shape\n",
    ")\n",
    "\n",
    "print(\"Model saved to %s\" % ready_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c173d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
